{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt \n",
    "import numpy as np \n",
    "import joblib \n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import make_model\n",
    "class feat_test_mdoel(make_model):\n",
    "    def __init__(self , name , clf , gamma ,x ,y , train_data_loc):\n",
    "        self.features = x.columns.to_list() \n",
    "        self.train_data_loc = train_data_loc\n",
    "        make_model.__init__(self , name , clf , gamma , x ,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['AGN' , 'STAR' , 'YSO' , 'HMXB' , 'LMXB' , 'ULX' , 'CV' , 'PULSAR']\n",
    "scores = ['precision' , 'recall' , 'f1_score']\n",
    "models = ['all_feat_v1' ,'no_color' , 'no_gal_coord' , 'no_IR' , 'no_mw' , 'no_optical_uv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_mean(file):\n",
    "    all_feat = {\n",
    "        'AGN' : {\n",
    "            'precision' : [] , \n",
    "            'recall' : [],\n",
    "            'f1_score' : []\n",
    "        } ,\n",
    "        'YSO' :{\n",
    "            'precision' : [] , \n",
    "            'recall' : [],\n",
    "            'f1_score' : []\n",
    "        },\n",
    "        'STAR' :{\n",
    "            'precision' : [] , \n",
    "            'recall' : [],\n",
    "            'f1_score' : []\n",
    "        },\n",
    "        'HMXB' :{\n",
    "            'precision' : [] , \n",
    "            'recall' : [],\n",
    "            'f1_score' : []\n",
    "        },\n",
    "        'LMXB' :{\n",
    "            'precision' : [] , \n",
    "            'recall' : [],\n",
    "            'f1_score' : []\n",
    "        } , \n",
    "        'ULX' :{\n",
    "            'precision' : [] , \n",
    "            'recall' : [],\n",
    "            'f1_score' : []\n",
    "        },\n",
    "        'CV':{\n",
    "            'precision' : [] , \n",
    "            'recall' : [],\n",
    "            'f1_score' : []\n",
    "        },\n",
    "        'PULSAR' :{\n",
    "            'precision' : [] , \n",
    "            'recall' : [],\n",
    "            'f1_score' : []\n",
    "        }\n",
    "    }\n",
    "    for l in labels:\n",
    "        for i in range(5):\n",
    "            model = joblib.load(f'models/{file}_{i}.pkl')\n",
    "            all_feat[l]['precision'].append(model.result['class_scores']['precision_score'][l])\n",
    "            all_feat[l]['recall'].append(model.result['class_scores']['recall_score'][l])\n",
    "            all_feat[l]['f1_score'].append(model.result['class_scores']['f1_score'][l])\n",
    "    all_mean = {}\n",
    "    for l in labels:\n",
    "        all_mean[l] = {}\n",
    "        for s in scores:\n",
    "            all_mean[l][s] = np.mean(all_feat[l][s])*100\n",
    "    all_std = {}\n",
    "    for l in labels:\n",
    "        all_std[l] = {}\n",
    "        for s in scores:\n",
    "            all_std[l][s] = np.std(all_feat[l][s])*100\n",
    "    mean_df = pd.DataFrame(all_mean)\n",
    "    std_df = pd.DataFrame(all_std)\n",
    "    return mean_df , std_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllllll}\n",
      "\\toprule\n",
      "{} &          AGN &         STAR &          YSO &         HMXB &         LMXB &          ULX &           CV &       PULSAR \\\\\n",
      "\\midrule\n",
      "precision &  96.8\\pm0.14 &  96.1\\pm0.08 &  92.8\\pm0.17 &  91.8\\pm0.24 &  94.8\\pm1.33 &  71.7\\pm1.23 &  60.6\\pm1.16 &  42.1\\pm1.93 \\\\\n",
      "recall    &  97.6\\pm0.15 &  95.7\\pm0.06 &  95.4\\pm0.25 &  90.7\\pm0.66 &  80.7\\pm0.84 &  71.2\\pm1.10 &  54.5\\pm1.50 &  45.3\\pm1.92 \\\\\n",
      "f1_score  &  97.2\\pm0.11 &  95.9\\pm0.07 &  94.1\\pm0.20 &  91.2\\pm0.36 &  87.2\\pm0.60 &  71.5\\pm1.05 &  57.4\\pm1.33 &  43.7\\pm1.89 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean , std = score_mean('all_feat_v1')\n",
    "for l in labels:\n",
    "    mean[l] = [f'{m:.1f}\\pm{s:.2f}' for m,s in zip(mean[l] , std[l])]\n",
    "print(mean.to_latex(escape=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
